{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Appendix.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zdestrion/ML_pvt_repo/blob/master/Appendix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1GwscQxWZfu",
        "colab_type": "text"
      },
      "source": [
        "# Pandas\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GJzUyPVWu28",
        "colab_type": "text"
      },
      "source": [
        "Pandas: prendere i dati da un file csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcDBTcubXIwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MOOexaDWj1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "filename=\"/content/drive/My Drive/Colab Notebooks/dataset/nome_file.csv\"\n",
        "df=pd.read_csv(filename,names=columns,engine='python')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS9EzuaTY84T",
        "colab_type": "text"
      },
      "source": [
        "selezionare features e organizzarle in una matrice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ohv0nJUVZCo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sel_features=['Total','HP','Attack','Defense','Sp. Atk','Sp. Def','Speed']\n",
        "X=df[sel_features].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkFPcAxmZRVS",
        "colab_type": "text"
      },
      "source": [
        "funzioni di pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WkygTxwbRnk",
        "colab_type": "text"
      },
      "source": [
        "series crea un oggetto (?) a partire da un vettore "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5ZOHd93ZVvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Series crea un vettore (?)\n",
        "data = np.array(['a','b','c','d'])\n",
        "s = pd.Series(data)\n",
        "\n",
        "print(s)\n",
        "print(s[3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvStBb32bjb7",
        "colab_type": "text"
      },
      "source": [
        "**.loc**\n",
        "\n",
        "per tutti gli elementi di colonna_1 che soddifano la condizione, sostituisce num in colonna_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrDpSysgbhNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.loc[(data['colonna_1']==condizione),'colonna_2']=num "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpOJIfQOeYRx",
        "colab_type": "text"
      },
      "source": [
        "posiziona in colonna 1 tutti gli elementi di colonna_2 che soddisfano una condizione"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBm5j84qc1jE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.loc[:,'colonna_1'] = df['colonna_2'] > num"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx6xm5m0fl2i",
        "colab_type": "text"
      },
      "source": [
        "**.count**\n",
        "\n",
        "conta gli elementi di un dataframe la quale colonna soddifa una condzione"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLsBOd2TflLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count=data[data['colonna'] == condizione].count()\n",
        "count['colonna']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I8j4P60kb0-",
        "colab_type": "text"
      },
      "source": [
        "PCA e TSNE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kyPxCEXkdrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "tsne = TSNE(n_components=50, init='pca', perplexity = 10)\n",
        "tsne_data = tsne.fit_transform(data[sel_features])\n",
        "data['tsne-one'] = tsne_data[:,0]\n",
        "data['tsne-two'] = tsne_data[:,1]\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "pca_result = pca.fit_transform(data[sel_features].values)\n",
        "\n",
        "data['pca-one'] = pca_result[:,0]\n",
        "data['pca-two'] = pca_result[:,1] \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZDHfL9HmN5S",
        "colab_type": "text"
      },
      "source": [
        "**plot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8XceROumPy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test_acc_sig.plot(kind='hist',y='PROB',color='blue',alpha=0.5,bins=np.linspace(0,1,10),label='Signal') #istogramma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o7RgoFMmuk6",
        "colab_type": "text"
      },
      "source": [
        "logistic regressor classificator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWbyz1Y3mt97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = SGDClassifier(loss=\"log\", penalty=\"l1\",alpha=alpha,max_iter=5,tol=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnHI9FJZpRWd",
        "colab_type": "text"
      },
      "source": [
        "normalizzare i dati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUC0cjv7pTd9",
        "colab_type": "code",
        "outputId": "e94b7028-364a-43ff-888c-2ca9c04a1203",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "X_norm= normalize(X, norm='l2') #gaussianizzo i dati\n",
        " \n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler=MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
        "scaler = MinMaxScaler()\n",
        "scaler=scaler.fit(data)\n",
        "print(scaler)\n",
        "X_scaled=scaler.transform(data)\n",
        "print(X_scaled)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
            "[[0.   0.  ]\n",
            " [0.25 0.25]\n",
            " [0.5  0.5 ]\n",
            " [1.   1.  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU95WENLXSL8",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessamento dati"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hq_yMZOBeeAU",
        "colab_type": "text"
      },
      "source": [
        "**leggere file txt con numpy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtN8m85pXRmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download del dataset:\n",
        "!wget http://www.roma1.infn.it/~giagu/datasets/ising2_label.dat\n",
        "!wget http://www.roma1.infn.it/~giagu/datasets/ising2_conf.dat\n",
        "\n",
        "data = np.loadtxt('file')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wi2qi2yZYCZN",
        "colab_type": "text"
      },
      "source": [
        "**Lettura dati con Keras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjORu8khel11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size = (100, 100)\n",
        "batch_size = 32\n",
        "\n",
        "#80% delle immagini usate per training - 20% per validation\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"Dataset\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    label_mode='categorical',\n",
        "    seed=4321,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "vali_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"Dataset\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    label_mode='categorical',\n",
        "    seed=4321,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "#lettura dataset di test\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"Dataset_test\",\n",
        "    label_mode='categorical',\n",
        "    seed=4321,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJR6Eot7YRvN",
        "colab_type": "text"
      },
      "source": [
        "**codificare le label usando one_hot encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OUuzKwzYGZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_onehot = keras.utils.to_categorical(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSVFBgnmYg10",
        "colab_type": "text"
      },
      "source": [
        "**dividere il campione in training e test sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fq-ccMOYgA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_to_test_ratio=0.8 # training samples\n",
        "\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(data,labels,train_size=train_to_test_ratio)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQayYK9wiWgu",
        "colab_type": "text"
      },
      "source": [
        "**normalizzazione delle immagini**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1u58MT2ianf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ottimizzazione dei dataset caching e prefetching per I/O su disco\n",
        "\n",
        "train_ds = train_ds.prefetch(buffer_size=32)\n",
        "vali_ds = vali_ds.prefetch(buffer_size=32)\n",
        "test_ds = test_ds.prefetch(buffer_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZdJ848_U46W",
        "colab_type": "text"
      },
      "source": [
        "**Leggere un immagine con keras da sito web**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG6esMmCVEC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_orig = keras.utils.get_file(\"IMG_4231.JPG\", \"http://giagu.web.cern.ch/giagu/CERN/IMG_4231.JPG\")\n",
        "\n",
        "img_size = (100,100)\n",
        "img_tmp = keras.preprocessing.image.load_img(img_orig, target_size=img_size)\n",
        "img_inp = keras.preprocessing.image.img_to_array(img_tmp) #->float32 Numpy array\n",
        "img_inp = np.expand_dims(img_inp, axis=0) #(100,100,3) -> (1,100,100,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GtV5GPrfsYz",
        "colab_type": "text"
      },
      "source": [
        "# Visualizzazione dati, immagini, filtri, heatmaps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0ittRWukMbr",
        "colab_type": "text"
      },
      "source": [
        "**Visualizzazione dataset di immagini acquisito con keras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPj6obMsfxhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_ds.take(1) fornisce un \"batch\" di immagini dal campione nel nostro caso 32 immagini\n",
        "for images, labels in train_ds.take(1):\n",
        "    print(images.shape)\n",
        "    print(labels.shape)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(int(np.argmax(labels[i]))) #ovviamente se le label sono one hot \n",
        "        plt.axis(\"off\")    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07lhzswQluNm",
        "colab_type": "text"
      },
      "source": [
        "**Visualizzazione uscita vari layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec0zg1pMlzYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#salviamo i nomi di tutti i layers della rete nella lista layer_names\n",
        "layer_names = []\n",
        "for layer in model.layers[:20]:\n",
        "    layer_names.append(layer.name)\n",
        "print(layer_names)\n",
        "\n",
        "# estraiamo gli output da tutti i 20 layers della nostra rete\n",
        "layer_outputs = [layer.output for layer in model.layers[:20]]\n",
        "\n",
        "# instanziamo un semplice modello keras che prende l'immagine in input e restituisce \n",
        "# tali output (le attivazioni)\n",
        "\n",
        "activation_model = keras.Model(inputs=model.input, outputs=layer_outputs)\n",
        "\n",
        "immagine = np.reshape(immagine, (1,100,100,3))\n",
        "\n",
        "# e estraiamone le attivazioni\n",
        "activations = activation_model.predict(immagine)\n",
        "\n",
        "layer_activation = activations[n] #n è l'indice della lista layer_names che voglio visualizare\n",
        "print(layer_activation.shape)\n",
        "\n",
        "k = 0\n",
        "plt.figure(figsize=(20, 5), frameon=False)\n",
        "\n",
        "for i in range(8):\n",
        "   for j in range(2):\n",
        "      ax = plt.subplot(2, 8, k + 1, sharex=ax)\n",
        "      plt.imshow(layer_activation[0, :, :, k], cmap='viridis') \n",
        "      plt.axis(\"off\")\n",
        "      plt.grid(False)\n",
        "      plt.title(layer_names[n])\n",
        "      k = k + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRDUHToFroW8",
        "colab_type": "text"
      },
      "source": [
        "**Visualizzazione filtri appresi dei layer convoluzionali**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMSGVuzuruN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for layerc in ['Conv_1', 'Conv_2', 'Conv_3']:\n",
        "    print('Filtri layer convoluzionale: ', layerc)\n",
        "    # pesi del layer selezionato:\n",
        "    filters, biases = model.get_layer(layerc).get_weights()\n",
        "    # numero dei filtri \n",
        "    print(filters.shape)\n",
        "    n_filters = filters.shape[3]\n",
        "    # numero canali \n",
        "    n_channels = filters.shape[2]\n",
        "    # normalizzazione in [0,1] per rendere più chiaro il plot\n",
        "    f_min, f_max = filters.min(), filters.max()\n",
        "    filters = (filters - f_min) / (f_max - f_min)\n",
        "    k = 1\n",
        "    plt.figure(figsize=(n_channels, n_filters*0.8), frameon=False)\n",
        "    for i in range(n_filters):\n",
        "        f = filters[:, :, :, i]\n",
        "        # plot del filtro per ogni canale RGB\n",
        "        for j in range(n_channels):\n",
        "            ax = plt.subplot(n_filters, n_channels, k)\n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks([])\n",
        "            plt.imshow(f[:, :, j], cmap='gray')\n",
        "            k = k + 1\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCwq9g_NsMFw",
        "colab_type": "text"
      },
      "source": [
        "**visualizzazione heatmaps**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTNJY1r7UVgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def make_gradcam_heatmap(\n",
        "    img_array, model, last_conv_layer_name, classifier_layer_names\n",
        "):\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last convolutional layer\n",
        "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
        "    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n",
        "\n",
        "    # Second, we create a model that maps the activations of the last convolutional\n",
        "    # layer to the final class predictions\n",
        "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
        "    x = classifier_input\n",
        "    for layer_name in classifier_layer_names:\n",
        "        x = model.get_layer(layer_name)(x)\n",
        "    classifier_model = keras.Model(classifier_input, x)\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Compute activations of the last conv layer and make the tape watch it\n",
        "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
        "        tape.watch(last_conv_layer_output)\n",
        "        # Compute class predictions\n",
        "        preds = classifier_model(last_conv_layer_output)\n",
        "        top_pred_index = tf.argmax(preds[0])\n",
        "        top_class_channel = preds[:, top_pred_index]\n",
        "\n",
        "    # This is the gradient of the top predicted class with regard to\n",
        "    # the output feature map of the last conv layer\n",
        "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
        "    pooled_grads = pooled_grads.numpy()\n",
        "    for i in range(pooled_grads.shape[-1]):\n",
        "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "    # The channel-wise mean of the resulting feature map\n",
        "    # is our heatmap of class activation\n",
        "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
        "    return heatmap\n",
        "\n",
        "\n",
        "# Preparazione immagine\n",
        "\n",
        "img_size = (100,100)\n",
        "img_tmp = keras.preprocessing.image.load_img(img_orig, target_size=img_size)\n",
        "img_inp = keras.preprocessing.image.img_to_array(img_tmp) #->float32 Numpy array\n",
        "img_inp = np.expand_dims(img_inp, axis=0) #(100,100,3) -> (1,100,100,3)\n",
        "\n",
        "preds = model.predict(img_inp)\n",
        "print(\"Classe predetta:\", np.argmax(preds))\n",
        "\n",
        "# Generate class activation heatmap\n",
        "last_conv_layer_name = \"MaxPool_3\"\n",
        "classifier_layer_names = [\n",
        "    \"Flatten\",\n",
        "    \"Dense_1\",\n",
        "    \"ReLU_dense_1\",\n",
        "    \"Dense_2\",\n",
        "    \"ReLU_dense_2\",\n",
        "    \"Output\",\n",
        "]\n",
        "\n",
        "\n",
        "heatmap = make_gradcam_heatmap(\n",
        "    img_inp, model, last_conv_layer_name, classifier_layer_names\n",
        ")\n",
        "\n",
        "# Display heatmap\n",
        "plt.matshow(heatmap)\n",
        "plt.title('class predicted %d'%np.argmax(preds))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjJc7u8ZfEGD",
        "colab_type": "text"
      },
      "source": [
        "# Rete neurale convoluzionale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2erjaxVDYurM",
        "colab_type": "text"
      },
      "source": [
        "**Creazione del modello CNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcJIpsdgY3rb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model definition (functional model)\n",
        "\n",
        "# definizione input (tensori 28 spin x 28 spin x 1)\n",
        "inputs = keras.Input(shape=(28,28,1))\n",
        "\n",
        "data_augmentation = keras.Sequential([\n",
        "  keras.layers.experimental.preprocessing.RandomFlip()\n",
        "], name='DataAugm')\n",
        "\n",
        "# Image augmentation block scomentare la riga che segue (e commentare la successiva) \n",
        "# per attivarlo\n",
        "#x = data_augmentation(inputs)\n",
        "x = inputs\n",
        "\n",
        "# primo blocco Convoluzionale\n",
        "x = keras.layers.Conv2D(32, kernel_size=(3,3), name='Conv_1')(x)\n",
        "x = keras.layers.ReLU(name='ReLU_1')(x)\n",
        "x = keras.layers.MaxPool2D((2,2), name='MaxPool_1')(x)\n",
        "\n",
        "# secondo blocco convoluzionale\n",
        "x = keras.layers.Conv2D(64, kernel_size=(3,3), name='Conv_2')(x)\n",
        "x = keras.layers.ReLU(name='ReLU_2')(x)\n",
        "x = keras.layers.MaxPool2D((2,2), name='MaxPool_2')(x)\n",
        "\n",
        "# terzo blocco convoluzionale (non applichiamo il maxpooling per non ridurre \n",
        "# troppo la dimensione dell'output x)\n",
        "x = keras.layers.Conv2D(64, kernel_size=(3,3), name='Conv_3')(x)\n",
        "x = keras.layers.ReLU(name='ReLU_3')(x)\n",
        "\n",
        "x = keras.layers.Flatten(name='Flatten')(x)\n",
        "# Layer denso\n",
        "x = keras.layers.Dense(256, name='Dense_1')(x)\n",
        "x = keras.layers.ReLU(name='ReLU_dense_1')(x)\n",
        "x = keras.layers.Dense(256, name='Dense_2')(x)\n",
        "x = keras.layers.ReLU(name='ReLU_dense_2')(x)\n",
        "outputs = keras.layers.Dense(1, name='Output')(x)\n",
        "\n",
        "#definizione del modello\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name='ising_CNN')\n",
        "\n",
        "#printout il summary del modello\n",
        "model.summary()\n",
        "\n",
        "# struttura el modello\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycXwKwvJZYMT",
        "colab_type": "text"
      },
      "source": [
        "**Compilazione del Modello**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUrHBBKCZZ-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LR_ST=1e-3\n",
        "\n",
        "OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=LR_ST)\n",
        "\n",
        "mse = tf.keras.losses.MeanSquaredError()\n",
        "mae = tf.keras.metrics.MeanAbsoluteError()\n",
        "\n",
        "EAGERLY = False\n",
        "\n",
        "model.compile(optimizer=OPTIMIZER,\n",
        "              loss=mse,\n",
        "              metrics=[mae],\n",
        "              run_eagerly=EAGERLY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh4Qa5xeZ9OL",
        "colab_type": "text"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6meQdr7VaAVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TRAINING\n",
        "\n",
        "def lr_decay(epoch):\n",
        "  if epoch < 10:\n",
        "    return LR_ST\n",
        "  else:\n",
        "    return LR_ST * tf.math.exp(0.2 * (10 - epoch))\n",
        "\n",
        "lr_scheduler = keras.callbacks.LearningRateScheduler(lr_decay)\n",
        "\n",
        "# callback per salvare il modello (solo i pesi in questo caso) ad ogni epoca\n",
        "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "        filepath='mycnn_{epoch}',\n",
        "        save_weights_only=True, \n",
        "        save_freq='epoch')\n",
        "\n",
        "#callbacks = [ lr_scheduler, model_checkpoint ]\n",
        "callbacks = [ model_checkpoint ]\n",
        "\n",
        "history = model.fit(X_train, Y_train, epochs=30, batch_size=128,\n",
        "                    validation_split=0.2, shuffle=True, verbose=1,\n",
        "                    callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s04FAbncaaM8",
        "colab_type": "text"
      },
      "source": [
        "**Caricare i dati col miglior validation score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBCVk-QBahOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_history=history.history['val_loss']\n",
        "best_epoch=np.argmin(loss_history)\n",
        "best_train_loss=loss_history[best_epoch]\n",
        "print('epoch with minimum validation loss: %d\\nvalidation loss: %f'%(best_epoch+1,best_train_loss))\n",
        "model.load_weights('mycnn_%d'%(best_epoch+1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OM6eLnola1Ol",
        "colab_type": "text"
      },
      "source": [
        "**Check accuracy and loss on test sample**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksP7fC4qa_YU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss, test_mae = model.evaluate(X_test,  Y_test, verbose=2)\n",
        "print('\\nTest loss (MSE):', test_loss)\n",
        "print('\\nTest MAE:', test_mae)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGjhj5wOc-8E",
        "colab_type": "text"
      },
      "source": [
        "**Accedere ai dati del training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKXICbQKdT8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mae = history.history['mean_absolute_error']\n",
        "val_mae = history.history['val_mean_absolute_error']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOVYihZ3bdt7",
        "colab_type": "text"
      },
      "source": [
        "# Plot training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQPhDTdacyI7",
        "colab_type": "text"
      },
      "source": [
        "**Plot (Loss e mae)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU4HryjUc32T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs_range = range(1, len(loss) + 1)\n",
        "\n",
        "plt.figure(figsize=(8*2, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, mae, label='Training MAE')\n",
        "plt.plot(epochs_range, val_mae, label='Validation MAE')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation MAE')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFkxg8debilL",
        "colab_type": "text"
      },
      "source": [
        "**Plot di confronto (Loss e Accuracy)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQseB1EmbmED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot della loss e della accuracy durante il training\n",
        "\n",
        "epochs_range = range(1, len(loss) + 1)\n",
        "\n",
        "plt.figure(figsize=(8, 8*2))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(epochs_range, loss2, label='Training Loss (dropout layer)')\n",
        "plt.plot(epochs_range, val_loss2, label='Validation Loss (dropout layer)')\n",
        "\n",
        "plt.plot(epochs_range, loss, label='Training Loss',color='tab:blue', linestyle='dashed')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss',color='tab:orange', linestyle='dashed')\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 8*2))\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(epochs_range, acc2, label='Training Accuracy (dropout layer)')\n",
        "plt.plot(epochs_range, val_acc2, label='Validation Accuracy (dropout layer)')\n",
        "\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy',color='tab:blue', linestyle='dashed')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy',color='tab:orange', linestyle='dashed')\n",
        "\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}